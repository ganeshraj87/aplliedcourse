{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bPfuVwYP4nCw"
   },
   "outputs": [],
   "source": [
    "# Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "IQSanVNq5YeZ",
    "outputId": "712e63c2-1792-4f87-8aaa-0bef51edd01f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "colab_type": "code",
    "id": "fIr4cHRX5Xjb",
    "outputId": "a8512daa-8b78-4f8e-e997-6b07a189d24c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: patool in /usr/local/lib/python3.6/dist-packages (1.12)\n",
      "patool: Extracting /content/drive/My Drive/HumanActivityRecognition.zip ...\n",
      "patool: running /usr/bin/7z x -o./Unpack_osvr88i7 -- \"/content/drive/My Drive/HumanActivityRecognition.zip\"\n",
      "patool: ... /content/drive/My Drive/HumanActivityRecognition.zip extracted to `HumanActivityRecognition1' (multiple files in root).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'HumanActivityRecognition1'"
      ]
     },
     "execution_count": 37,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "!pip3 install patool\n",
    "import patoolib\n",
    "patoolib.extract_archive('/content/drive/My Drive/HumanActivityRecognition.zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5TjZYC0S4nC9"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6eX9G-W14nDF"
   },
   "outputs": [],
   "source": [
    "# Activities are the class labels\n",
    "# It is a 6 class classification\n",
    "ACTIVITIES = {\n",
    "    0: 'WALKING',\n",
    "    1: 'WALKING_UPSTAIRS',\n",
    "    2: 'WALKING_DOWNSTAIRS',\n",
    "    3: 'SITTING',\n",
    "    4: 'STANDING',\n",
    "    5: 'LAYING',\n",
    "}\n",
    "\n",
    "# Utility function to print the confusion matrix\n",
    "def confusion_matrix(Y_true, Y_pred):\n",
    "    Y_true = pd.Series([ACTIVITIES[y] for y in np.argmax(Y_true, axis=1)])\n",
    "    Y_pred = pd.Series([ACTIVITIES[y] for y in np.argmax(Y_pred, axis=1)])\n",
    "    return pd.crosstab(Y_true, Y_pred, rownames=['True'], colnames=['Pred'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "w_XAdzM24nDM"
   },
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ol1aYZBv4nDP"
   },
   "outputs": [],
   "source": [
    "# Data directory\n",
    "DATADIR = 'UCI_HAR_Dataset'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "E6v-8k0d4nDW"
   },
   "outputs": [],
   "source": [
    "# Raw data signals\n",
    "# Signals are from Accelerometer and Gyroscope\n",
    "# The signals are in x,y,z directions\n",
    "# Sensor signals are filtered to have only body acceleration\n",
    "# excluding the acceleration due to gravity\n",
    "# Triaxial acceleration from the accelerometer is total acceleration\n",
    "SIGNALS = [\n",
    "    \"body_acc_x\",\n",
    "    \"body_acc_y\",\n",
    "    \"body_acc_z\",\n",
    "    \"body_gyro_x\",\n",
    "    \"body_gyro_y\",\n",
    "    \"body_gyro_z\",\n",
    "    \"total_acc_x\",\n",
    "    \"total_acc_y\",\n",
    "    \"total_acc_z\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0qnMjxat4nDd"
   },
   "outputs": [],
   "source": [
    "# Utility function to read the data from csv file\n",
    "def _read_csv(filename):\n",
    "    return pd.read_csv(filename, delim_whitespace=True, header=None)\n",
    "\n",
    "# Utility function to load the load\n",
    "def load_signals(subset):\n",
    "    signals_data = []\n",
    "\n",
    "    for signal in SIGNALS:\n",
    "        filename = f'/content/HumanActivityRecognition/HAR/UCI_HAR_Dataset/{subset}/Inertial Signals/{signal}_{subset}.txt'\n",
    "        signals_data.append(\n",
    "            _read_csv(filename).as_matrix()\n",
    "        ) \n",
    "\n",
    "    # Transpose is used to change the dimensionality of the output,\n",
    "    # aggregating the signals by combination of sample/timestep.\n",
    "    # Resultant shape is (7352 train/2947 test samples, 128 timesteps, 9 signals)\n",
    "    return np.transpose(signals_data, (1, 2, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NKVqn2g14nDm"
   },
   "outputs": [],
   "source": [
    "\n",
    "def load_y(subset):\n",
    "    \"\"\"\n",
    "    The objective that we are trying to predict is a integer, from 1 to 6,\n",
    "    that represents a human activity. We return a binary representation of \n",
    "    every sample objective as a 6 bits vector using One Hot Encoding\n",
    "    (https://pandas.pydata.org/pandas-docs/stable/generated/pandas.get_dummies.html)\n",
    "    \"\"\"\n",
    "   \n",
    "    filename = f'/content/HumanActivityRecognition/HAR/UCI_HAR_Dataset/{subset}/y_{subset}.txt'\n",
    "    y = _read_csv(filename)[0]\n",
    "\n",
    "    return pd.get_dummies(y).as_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Tzkjp4A24nDt"
   },
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    \"\"\"\n",
    "    Obtain the dataset from multiple files.\n",
    "    Returns: X_train, X_test, y_train, y_test\n",
    "    \"\"\"\n",
    "    X_train, X_test = load_signals('train'), load_signals('test')\n",
    "    y_train, y_test = load_y('train'), load_y('test')\n",
    "\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "B1Qz2Der4nD1"
   },
   "outputs": [],
   "source": [
    "# Importing tensorflow\n",
    "np.random.seed(42)\n",
    "import tensorflow as tf\n",
    "tf.set_random_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cqBifQ1V4nD9"
   },
   "outputs": [],
   "source": [
    "# Configuring a session\n",
    "session_conf = tf.ConfigProto(\n",
    "    intra_op_parallelism_threads=1,\n",
    "    inter_op_parallelism_threads=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NUff6Bmd4nEI"
   },
   "outputs": [],
   "source": [
    "# Import Keras\n",
    "from keras import backend as K\n",
    "sess = tf.Session(graph=tf.get_default_graph(), config=session_conf)\n",
    "K.set_session(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PV6rVx1j4nEO"
   },
   "outputs": [],
   "source": [
    "# Importing libraries\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM\n",
    "from keras.layers.core import Dense, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4-4UbJlX4nEa"
   },
   "outputs": [],
   "source": [
    "# Utility function to count the number of classes\n",
    "def _count_classes(y):\n",
    "    return len(set([tuple(category) for category in y]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "6ptV0Z8O4nEh",
    "outputId": "7d086921-5600-4257-9f1e-2a56f500e1af"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:11: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:13: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  del sys.path[0]\n"
     ]
    }
   ],
   "source": [
    "# Loading the train and test data\n",
    "X_train, X_test, Y_train, Y_test = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "3C3YyHHD4nEn",
    "outputId": "94cf07e5-f866-4558-9d3d-7cd56e81fbb8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "128\n",
      "9\n",
      "7352\n"
     ]
    }
   ],
   "source": [
    "timesteps = len(X_train[0])\n",
    "input_dim = len(X_train[0][0])\n",
    "n_classes = _count_classes(Y_train)\n",
    "\n",
    "print(timesteps)\n",
    "print(input_dim)\n",
    "print(len(X_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DqEKELgc4nEv"
   },
   "source": [
    "- Defining the Architecture of CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 629
    },
    "colab_type": "code",
    "id": "GKRzvx4N4nEx",
    "outputId": "503ef4cb-a575-4d93-87a4-3dfc43a60b02"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_5 (Conv1D)            (None, 126, 32)           896       \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 126, 32)           128       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_5 (MaxPooling1 (None, 63, 32)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_6 (Conv1D)            (None, 61, 48)            4656      \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 61, 48)            192       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_6 (MaxPooling1 (None, 30, 48)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_7 (Conv1D)            (None, 28, 64)            9280      \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 28, 64)            256       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_7 (MaxPooling1 (None, 14, 64)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_8 (Conv1D)            (None, 10, 128)           41088     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_8 (MaxPooling1 (None, 2, 128)            0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 16)                4112      \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 6)                 102       \n",
      "=================================================================\n",
      "Total params: 60,710\n",
      "Trainable params: 60,422\n",
      "Non-trainable params: 288\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Initiliazing the sequential model\n",
    "model = Sequential()\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.models import load_model\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers import Dense, Activation, Flatten\n",
    "\n",
    "from keras.layers.convolutional import Conv1D ,MaxPooling1D\n",
    "\n",
    "model_BN = Sequential()\n",
    "model_BN.add(Conv1D(32,3,activation='relu',padding='valid',input_shape=(timesteps, input_dim)))\n",
    "model_BN.add(BatchNormalization())\n",
    "model_BN.add(MaxPooling1D(pool_size=2))\n",
    "model_BN.add(Conv1D(48,3, padding='valid', activation='relu'))\n",
    "model_BN.add(BatchNormalization())\n",
    "model_BN.add(MaxPooling1D(pool_size=2))\n",
    "model_BN.add(Conv1D(64,3, padding='valid', activation='relu'))\n",
    "model_BN.add(BatchNormalization())\n",
    "model_BN.add(MaxPooling1D(pool_size=2))\n",
    "model_BN.add(Conv1D(128,5,padding='valid',activation='relu'))\n",
    "model_BN.add(MaxPooling1D(pool_size=4))\n",
    "model_BN.add(Flatten())\n",
    "model_BN.add(Dense(16, activation='relu'))\n",
    "model_BN.add(Dense(n_classes, activation='softmax'))\n",
    "model_BN.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "iEumPPg-4nE3",
    "outputId": "6897b598-c5f8-4933-caf7-c3ffdd94a379"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7352 samples, validate on 2947 samples\n",
      "Epoch 1/15\n",
      "7352/7352 [==============================] - 7s 889us/step - loss: 0.0994 - acc: 0.9596 - val_loss: 0.2548 - val_acc: 0.9267\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.92671, saving model to /content/HumanActivityRecognition/HAR/epochs:001-val_acc:0.927.hdf5\n",
      "Epoch 2/15\n",
      "7352/7352 [==============================] - 5s 684us/step - loss: 0.0814 - acc: 0.9657 - val_loss: 0.2947 - val_acc: 0.9335\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.92671 to 0.93349, saving model to /content/HumanActivityRecognition/HAR/epochs:002-val_acc:0.933.hdf5\n",
      "Epoch 3/15\n",
      "7352/7352 [==============================] - 5s 711us/step - loss: 0.0981 - acc: 0.9645 - val_loss: 0.3924 - val_acc: 0.9304\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 0.93349\n",
      "Epoch 4/15\n",
      "7352/7352 [==============================] - 5s 694us/step - loss: 0.0962 - acc: 0.9627 - val_loss: 0.3372 - val_acc: 0.9355\n",
      "\n",
      "Epoch 00004: val_acc improved from 0.93349 to 0.93553, saving model to /content/HumanActivityRecognition/HAR/epochs:004-val_acc:0.936.hdf5\n",
      "Epoch 5/15\n",
      "7352/7352 [==============================] - 5s 743us/step - loss: 0.0716 - acc: 0.9717 - val_loss: 0.3508 - val_acc: 0.9301\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.93553\n",
      "Epoch 6/15\n",
      "7352/7352 [==============================] - 5s 697us/step - loss: 0.0890 - acc: 0.9640 - val_loss: 0.4023 - val_acc: 0.9186\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.93553\n",
      "Epoch 7/15\n",
      "7352/7352 [==============================] - 5s 676us/step - loss: 0.0829 - acc: 0.9680 - val_loss: 0.4176 - val_acc: 0.9335\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.93553\n",
      "Epoch 8/15\n",
      "7352/7352 [==============================] - 5s 697us/step - loss: 0.0741 - acc: 0.9690 - val_loss: 0.4678 - val_acc: 0.9348\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.93553\n",
      "Epoch 9/15\n",
      "7352/7352 [==============================] - 5s 691us/step - loss: 0.0765 - acc: 0.9693 - val_loss: 0.4397 - val_acc: 0.9264\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.93553\n",
      "Epoch 10/15\n",
      "7352/7352 [==============================] - 5s 671us/step - loss: 0.0655 - acc: 0.9736 - val_loss: 0.4522 - val_acc: 0.9382\n",
      "\n",
      "Epoch 00010: val_acc improved from 0.93553 to 0.93824, saving model to /content/HumanActivityRecognition/HAR/epochs:010-val_acc:0.938.hdf5\n",
      "Epoch 11/15\n",
      "7352/7352 [==============================] - 5s 649us/step - loss: 0.0702 - acc: 0.9724 - val_loss: 0.3408 - val_acc: 0.9389\n",
      "\n",
      "Epoch 00011: val_acc improved from 0.93824 to 0.93892, saving model to /content/HumanActivityRecognition/HAR/epochs:011-val_acc:0.939.hdf5\n",
      "Epoch 12/15\n",
      "7352/7352 [==============================] - 5s 695us/step - loss: 0.0701 - acc: 0.9717 - val_loss: 0.3625 - val_acc: 0.9420\n",
      "\n",
      "Epoch 00012: val_acc improved from 0.93892 to 0.94197, saving model to /content/HumanActivityRecognition/HAR/epochs:012-val_acc:0.942.hdf5\n",
      "Epoch 13/15\n",
      "7352/7352 [==============================] - 5s 654us/step - loss: 0.0656 - acc: 0.9721 - val_loss: 0.4574 - val_acc: 0.9291\n",
      "\n",
      "Epoch 00013: val_acc did not improve from 0.94197\n",
      "Epoch 14/15\n",
      "7352/7352 [==============================] - 5s 690us/step - loss: 0.0701 - acc: 0.9724 - val_loss: 0.7031 - val_acc: 0.9036\n",
      "\n",
      "Epoch 00014: val_acc did not improve from 0.94197\n",
      "Epoch 15/15\n",
      "7352/7352 [==============================] - 5s 674us/step - loss: 0.0606 - acc: 0.9735 - val_loss: 0.5487 - val_acc: 0.9111\n",
      "\n",
      "Epoch 00015: val_acc did not improve from 0.94197\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7efbbf7ca710>"
      ]
     },
     "execution_count": 59,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compiling the model\n",
    "# https://machinelearningmastery.com/check-point-deep-learning-models-keras/\n",
    "from keras.callbacks import *\n",
    "filepath=\"/content/HumanActivityRecognition/HAR/epochs:{epoch:03d}-val_acc:{val_acc:.3f}.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
    "callbacks_list = [checkpoint]\n",
    "\n",
    "\n",
    "\n",
    "model_BN.compile(loss='categorical_crossentropy',optimizer='Adam', metrics=['accuracy'])\n",
    "model_BN.fit(X_train,Y_train,batch_size=16,validation_data=(X_test, Y_test),epochs=15,callbacks=callbacks_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dZf2o4Xtel0n"
   },
   "outputs": [],
   "source": [
    "model_BN.load_weights(\"/content/HumanActivityRecognition/HAR/epochs:012-val_acc:0.942.hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "miKS8HByCFNB"
   },
   "outputs": [],
   "source": [
    "Y_true = pd.Series([ACTIVITIES[y] for y in np.argmax(Y_test, axis=1)])\n",
    "Y_pred = pd.Series([ACTIVITIES[y] for y in np.argmax(model_BN.predict(X_test), axis=1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 266
    },
    "colab_type": "code",
    "id": "z-pp3_qsCRFf",
    "outputId": "1f2b0c62-816e-4815-8ac0-3215cc9c1401"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Pred</th>\n",
       "      <th>LAYING</th>\n",
       "      <th>SITTING</th>\n",
       "      <th>STANDING</th>\n",
       "      <th>WALKING</th>\n",
       "      <th>WALKING_DOWNSTAIRS</th>\n",
       "      <th>WALKING_UPSTAIRS</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LAYING</th>\n",
       "      <td>537</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SITTING</th>\n",
       "      <td>22</td>\n",
       "      <td>407</td>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>STANDING</th>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>512</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WALKING</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>471</td>\n",
       "      <td>11</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WALKING_DOWNSTAIRS</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>419</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WALKING_UPSTAIRS</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>27</td>\n",
       "      <td>430</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Pred                LAYING  SITTING  ...  WALKING_DOWNSTAIRS  WALKING_UPSTAIRS\n",
       "True                                 ...                                      \n",
       "LAYING                 537        0  ...                   0                 0\n",
       "SITTING                 22      407  ...                   0                 2\n",
       "STANDING                 0       19  ...                   0                 0\n",
       "WALKING                  0        0  ...                  11                13\n",
       "WALKING_DOWNSTAIRS       0        0  ...                 419                 1\n",
       "WALKING_UPSTAIRS         0        2  ...                  27               430\n",
       "\n",
       "[6 rows x 6 columns]"
      ]
     },
     "execution_count": 62,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.crosstab(Y_true, Y_pred, rownames=['True'], colnames=['Pred'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "CwNdKRG14nFJ",
    "outputId": "9095b24a-ccc1-417d-f8e2-bff2ce8a0397"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2947/2947 [==============================] - 0s 161us/step\n"
     ]
    }
   ],
   "source": [
    "score = model_BN.evaluate(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "ce-3ypQM4nFO",
    "outputId": "d2fa88b7-aab7-499c-9300-ccb641f3f169"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.3624597953069845, 0.9419748897183576]"
      ]
     },
     "execution_count": 64,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VcURu_ht4nFU"
   },
   "source": [
    "- With a CNN architecture with Batch Normalization and Maxpooling we got 94.19% accuracy and a loss of 0.3624 from our best model\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "HAR_CNN_BN_Maxpooling.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
